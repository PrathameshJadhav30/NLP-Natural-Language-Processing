{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Parts of Speech tagging in NLP."
      ],
      "metadata": {
        "id": "RVlM4M0KnO6O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v2YQc9tOfZF-"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqelj5QBivWG",
        "outputId": "c6e9fc85-7a3e-4869-b560-ef42e7c7dd1b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"I am Prathamesh Jadhav And Currently I am Performing POS Tagging Experiment.\""
      ],
      "metadata": {
        "id": "bFuaMNNphsR2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenization\n",
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "wkPqKbI4hyMX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: POS Tagging\n",
        "tagged_words = pos_tag(tokens)"
      ],
      "metadata": {
        "id": "iBSQyIf5hzku"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output result\n",
        "print(\"Tokenized Words:\", tokens)\n",
        "print(\"POS Tagged Words:\")\n",
        "for word, tag in tagged_words:\n",
        "    print(f\"{word} -> {tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2CSgy3ch5UY",
        "outputId": "5c32d8dd-6a0e-444d-9a67-8a9ea55eb615"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['I', 'am', 'Prathamesh', 'Jadhav', 'And', 'Currently', 'I', 'am', 'Performing', 'POS', 'Tagging', 'Experiment', '.']\n",
            "POS Tagged Words:\n",
            "I -> PRP\n",
            "am -> VBP\n",
            "Prathamesh -> JJ\n",
            "Jadhav -> NNP\n",
            "And -> CC\n",
            "Currently -> NNP\n",
            "I -> PRP\n",
            "am -> VBP\n",
            "Performing -> VBG\n",
            "POS -> NNP\n",
            "Tagging -> NNP\n",
            "Experiment -> NNP\n",
            ". -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Code IN One Block"
      ],
      "metadata": {
        "id": "xXGnXrfkqCTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Sample text\n",
        "text = \"I am Prathamesh Jadhav And Currently I am Performing POS Tagging Experiment.\"\n",
        "\n",
        "# Step 1: Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Step 2: POS Tagging\n",
        "tagged_words = pos_tag(tokens)\n",
        "\n",
        "# Output result\n",
        "print(\"Tokenized Words:\", tokens)\n",
        "print(\"POS Tagged Words:\")\n",
        "for word, tag in tagged_words:\n",
        "    print(f\"{word} -> {tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWzlnLvUmsNJ",
        "outputId": "92d115dc-2660-46b2-f72e-7cee63818845"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['I', 'am', 'Prathamesh', 'Jadhav', 'And', 'Currently', 'I', 'am', 'Performing', 'POS', 'Tagging', 'Experiment', '.']\n",
            "POS Tagged Words:\n",
            "I -> PRP\n",
            "am -> VBP\n",
            "Prathamesh -> JJ\n",
            "Jadhav -> NNP\n",
            "And -> CC\n",
            "Currently -> NNP\n",
            "I -> PRP\n",
            "am -> VBP\n",
            "Performing -> VBG\n",
            "POS -> NNP\n",
            "Tagging -> NNP\n",
            "Experiment -> NNP\n",
            ". -> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Activity with Visualization"
      ],
      "metadata": {
        "id": "IzstidjuqJVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from tabulate import tabulate\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Sample Text\n",
        "text = \"Data Science combines statistics, computer science, and domain knowledge to extract insights.\"\n",
        "\n",
        "# Tokenize and tag\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Display as table\n",
        "print(tabulate(tags, headers=[\"Word\", \"POS Tag\"], tablefmt=\"grid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1IUR8bFqIdf",
        "outputId": "8495aee4-b9fb-4207-91da-c7f6a8520ead"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Word       | POS Tag   |\n",
            "+============+===========+\n",
            "| Data       | NNP       |\n",
            "+------------+-----------+\n",
            "| Science    | NNP       |\n",
            "+------------+-----------+\n",
            "| combines   | NNS       |\n",
            "+------------+-----------+\n",
            "| statistics | NNS       |\n",
            "+------------+-----------+\n",
            "| ,          | ,         |\n",
            "+------------+-----------+\n",
            "| computer   | NN        |\n",
            "+------------+-----------+\n",
            "| science    | NN        |\n",
            "+------------+-----------+\n",
            "| ,          | ,         |\n",
            "+------------+-----------+\n",
            "| and        | CC        |\n",
            "+------------+-----------+\n",
            "| domain     | VB        |\n",
            "+------------+-----------+\n",
            "| knowledge  | NN        |\n",
            "+------------+-----------+\n",
            "| to         | TO        |\n",
            "+------------+-----------+\n",
            "| extract    | VB        |\n",
            "+------------+-----------+\n",
            "| insights   | NNS       |\n",
            "+------------+-----------+\n",
            "| .          | .         |\n",
            "+------------+-----------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}